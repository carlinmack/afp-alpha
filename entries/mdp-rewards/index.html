<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1"><title>Markov Decision Processes with Rewards - Archive of Formal Proofs</title><meta name=description content="
We present a formalization of Markov Decision Processes with rewards.
In particular we first build on Hölzl's formalization  of MDPs
(AFP entry:..."><meta property="og:title" content="Markov Decision Processes with Rewards">
<meta property="og:description" content>
<meta property="og:type" content="article">
<meta property="og:url" content="/entries/mdp-rewards/"><meta property="og:image" content="/images/afp.png"><meta property="article:section" content="entries">
<meta property="article:published_time" content="2021-12-16T00:00:00+00:00">
<meta property="article:modified_time" content="2021-12-16T00:00:00+00:00"><meta property="og:site_name" content="Archive of Formal Proofs">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="/images/afp.png">
<meta name=twitter:title content="Markov Decision Processes with Rewards">
<meta name=twitter:description content>
<link rel=stylesheet type=text/css href=/css/front.min.css>
<link rel=icon href=/images/favicon.ico type=image/icon>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},processEscapes:!0,svg:{fontCache:'global'}}</script>
<script id=MathJax-script async src=/js/mathjax/es5/tex-mml-chtml.js></script>
<script src=/js/entries.js></script><script src=/js/flexsearch.min.js></script>
<script src=/js/banner.js></script><script src=/js/header-search.js></script></head>
<body class=mathjax_ignore>
<aside>
<div>
<div>
<a href=/>
<img src=/images/afp.png alt="Logo of the Archive of Formal Proofs" class=logo>
</a>
<ul>
<li><a href=/>Home</a></li>
<li><a href=/topics/>Topics</a></li>
<li><a href=/download/>Download</a></li>
<li><a href=/help/>Help</a></li>
<li><a href=/statistics/>Statistics</a></li>
<li><a href=/about/>About</a></li>
</ul>
</div>
<ul>
<li><a href=/contribution/>Contribution</a></li>
</ul>
</div>
</aside>
<div class="content entries"><header>
<form action=/%20search>
<div class=form-container>
<input id=searchInput type=search size=31 maxlength=255 aria-label="Search the AFP" list=autocomplete><button id=searchButton type=button><img src=/images/search.svg alt=Search></button>
<datalist id=autocomplete>
</datalist>
</div>
</form>
<h1><span class=first>M</span>arkov <span class=first>D</span>ecision <span class=first>P</span>rocesses <span class=first>W</span>ith <span class=first>R</span>ewards</h1>
<div>
<p><a href=/authors/maximilian-sch%C3%A4ffeler>Maximilian Schäffeler</a> and <a href=/authors/mohammad-abdulaziz>Mohammad Abdulaziz</a>
</p>
<p class=date>16 December 2021</p>
</div>
</header><div id=banner data-id=0>
<p>This is an unofficial reimagining of the <a href=https://isa-afp.org target=_blank rel="noreferrer noopener">Archive of Formal Proofs</a></p><button style=display:none id=close title=close><svg viewBox="0 0 6.718 6.718" aria-hidden="true" focusable="false"><rect transform="rotate(45)" x="4" y="-4" width="1.5" height="8"/><rect transform="rotate(45)" x=".75" y="-.75" width="8" height="1.5"/></svg></button>
</div>
<div><main>
<h3>Abstract</h3>
<div class="abstract mathjax_process">We present a formalization of Markov Decision Processes with rewards.
In particular we first build on Hölzl's formalization of MDPs
(AFP entry: Markov_Models) and extend them with rewards. We proceed
with an analysis of the expected total discounted reward criterion for
infinite horizon MDPs. The central result is the construction of the
iteration rule for the Bellman operator. We prove the optimality
equations for this operator and show the existence of an optimal
stationary deterministic solution. The analysis can be used to obtain
dynamic programming algorithms such as value iteration and policy
iteration to solve MDPs with formal guarantees. Our formalization is
based on chapters 5 and 6 in Puterman's book "Markov
Decision Processes: Discrete Stochastic Dynamic Programming".</div><a href=http://isa-afp.org/LICENSE>BSD License</a><h3>Used by</h3>
<ul><li><a href=/entries/mdp-algorithms/>MDP-Algorithms</a></li></ul><h3>Topics</h3>
<ul><li><a href=/topics/mathematics/probability-theory>Mathematics/Probability theory</a></li></ul><h3>Theories</h3>
<ul>
<li><a href=theories/#Bounded_Functions>Bounded_Functions</a></li><li><a href=theories/#Blinfun_Util>Blinfun_Util</a></li><li><a href=theories/#MDP_reward_Util>MDP_reward_Util</a></li><li><a href=theories/#MDP_cont>MDP_cont</a></li><li><a href=theories/#MDP_disc>MDP_disc</a></li><li><a href=theories/#MDP_reward>MDP_reward</a></li></ul>
</main>
<nav class=links>
<a class=popUpButton href=#citePopUp>Cite</a>
<a class=popUpButton href=#downloadPopUp>Download</a>
<h4>PDFs</h4>
<a href=https://www.isa-afp.org/browser_info/current/AFP/MDP-Rewards/outline.pdf>Proof
outline</a>
<a href=https://www.isa-afp.org/browser_info/current/AFP/MDP-Rewards/document.pdf>Proof
document</a>
<a href=https://www.isa-afp.org/browser_info/current/AFP/MDP-Rewards/session_graph.pdf>Dependencies</a>
</nav>
<div id=citePopUp class=overlay>
<a class=cancel href=#></a>
<div class=popup>
<h2>Cite</h2>
<a class=close href=#>&#215;</a>
<div>
<p style=display:none id=bibtexFileName>MDP-Rewards-AFP</p>
<pre id=copyText>@article{MDP-Rewards-AFP,
  author  = {Maximilian Schäffeler and Mohammad Abdulaziz},
  title   = {Markov Decision Processes with Rewards},
  journal = {Archive of Formal Proofs},
  month   = December,
  year    = 2021,
  note    = {\url{http://isa-afp.org/entries/MDP-Rewards.html},
            Formal proof development},
  ISSN    = {2150-914x},
}</pre>
<button id=copyBibtex>Copy</button> <a id=downloadBibtex>Download</a>
</div>
</div>
</div>
<div id=downloadPopUp class=overlay>
<a class=cancel href=#></a>
<div class=popup>
<h2>Download</h2>
<a class=close href=#>&#215;</a>
<a href=https://isa-afp.org/release/afp-MDP-Rewards-current.tar.gz download>Download latest</a>
</div>
</div>
</div>
</div>
</body>
</html>