<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1"><title>Expressiveness of Deep Learning - Archive of Formal Proofs</title><meta name=description content="
Deep learning has had a profound impact on computer science in recent years, with applications to search engines, image recognition and language..."><meta property="og:title" content="Expressiveness of Deep Learning">
<meta property="og:description" content>
<meta property="og:type" content="article">
<meta property="og:url" content="/entries/deep_learning/"><meta property="og:image" content="/images/afp.png"><meta property="article:section" content="entries">
<meta property="article:published_time" content="2016-11-10T00:00:00+00:00">
<meta property="article:modified_time" content="2016-11-10T00:00:00+00:00"><meta property="og:site_name" content="Archive of Formal Proofs">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="/images/afp.png">
<meta name=twitter:title content="Expressiveness of Deep Learning">
<meta name=twitter:description content>
<link rel=stylesheet type=text/css href=/css/front.min.css>
<link rel=icon href=/images/favicon.ico type=image/icon>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},processEscapes:!0,svg:{fontCache:'global'}}</script>
<script id=MathJax-script async src=/js/mathjax/es5/tex-mml-chtml.js></script>
<script src=/js/entries.js></script><script src=/js/flexsearch.min.js></script>
<script src=/js/banner.js></script><script src=/js/header-search.js></script></head>
<body class=mathjax_ignore>
<aside>
<div>
<div>
<a href=/>
<img src=/images/afp.png alt="Logo of the Archive of Formal Proofs" class=logo>
</a>
<ul>
<li><a href=/>Home</a></li>
<li><a href=/topics/>Topics</a></li>
<li><a href=/download/>Download</a></li>
<li><a href=/help/>Help</a></li>
<li><a href=/statistics/>Statistics</a></li>
<li><a href=/about/>About</a></li>
</ul>
</div>
<ul>
<li><a href=/contribution/>Contribution</a></li>
</ul>
</div>
</aside>
<div class="content entries"><header>
<form action=/%20search>
<div class=form-container>
<input id=searchInput type=search size=31 maxlength=255 aria-label="Search the AFP" list=autocomplete><button id=searchButton type=button><img src=/images/search.svg alt=Search></button>
<datalist id=autocomplete>
</datalist>
</div>
</form>
<h1><span class=first>E</span>xpressiveness of <span class=first>D</span>eep <span class=first>L</span>earning</h1>
<div>
<p><a href=/authors/alexander-bentkamp>Alexander Bentkamp</a>
</p>
<p class=date>10 November 2016</p>
</div>
</header><div id=banner data-id=0>
<p>This is an unofficial reimagining of the <a href=https://isa-afp.org target=_blank rel="noreferrer noopener">Archive of Formal Proofs</a></p><button style=display:none id=close title=close><svg viewBox="0 0 6.718 6.718" aria-hidden="true" focusable="false"><rect transform="rotate(45)" x="4" y="-4" width="1.5" height="8"/><rect transform="rotate(45)" x=".75" y="-.75" width="8" height="1.5"/></svg></button>
</div>
<div><main>
<h3>Abstract</h3>
<div class="abstract mathjax_process">Deep learning has had a profound impact on computer science in recent years, with applications to search engines, image recognition and language processing, bioinformatics, and more. Recently, Cohen et al. provided theoretical evidence for the superiority of deep learning over shallow learning. This formalization of their work simplifies and generalizes the original proof, while working around the limitations of the Isabelle type system. To support the formalization, I developed reusable libraries of formalized mathematics, including results about the matrix rank, the Lebesgue measure, and multivariate polynomials, as well as a library for tensor analysis.</div><a href=http://isa-afp.org/LICENSE>BSD License</a><h3>Depends On</h3><ul><li><a href=/entries/jordan_normal_form>Jordan_Normal_Form</a></li><li><a href=/entries/polynomial_interpolation>Polynomial_Interpolation</a></li><li><a href=/entries/polynomials>Polynomials</a></li><li><a href=/entries/vectorspace>VectorSpace</a></li></ul><h3>Used by</h3>
<ul><li><a href=/entries/qhlprover/>QHLProver</a></li></ul><h3>Topics</h3>
<ul><li><a href=/topics/computer-science/machine-learning>Computer science/Machine learning</a></li><li><a href=/topics/mathematics/analysis>Mathematics/Analysis</a></li></ul><h3>Related Entries</h3>
<ul><li><a href=/entries/groebner_bases>Groebner_Bases</a></li><li><a href=/entries/isabelle_marries_dirac>Isabelle_Marries_Dirac</a></li></ul><h3>Theories</h3>
<ul>
<li><a href=theories/#Tensor>Tensor</a></li><li><a href=theories/#Tensor_Subtensor>Tensor_Subtensor</a></li><li><a href=theories/#Tensor_Plus>Tensor_Plus</a></li><li><a href=theories/#Tensor_Scalar_Mult>Tensor_Scalar_Mult</a></li><li><a href=theories/#Tensor_Product>Tensor_Product</a></li><li><a href=theories/#Tensor_Unit_Vec>Tensor_Unit_Vec</a></li><li><a href=theories/#Tensor_Rank>Tensor_Rank</a></li><li><a href=theories/#Tensor_Matricization>Tensor_Matricization</a></li><li><a href=theories/#DL_Rank_CP_Rank>DL_Rank_CP_Rank</a></li><li><a href=theories/#DL_Flatten_Matrix>DL_Flatten_Matrix</a></li><li><a href=theories/#DL_Network>DL_Network</a></li><li><a href=theories/#DL_Concrete_Matrices>DL_Concrete_Matrices</a></li><li><a href=theories/#DL_Missing_Finite_Set>DL_Missing_Finite_Set</a></li><li><a href=theories/#DL_Deep_Model>DL_Deep_Model</a></li><li><a href=theories/#DL_Deep_Model_Poly>DL_Deep_Model_Poly</a></li><li><a href=theories/#Lebesgue_Functional>Lebesgue_Functional</a></li><li><a href=theories/#Lebesgue_Zero_Set>Lebesgue_Zero_Set</a></li><li><a href=theories/#DL_Shallow_Model>DL_Shallow_Model</a></li><li><a href=theories/#DL_Fundamental_Theorem_Network_Capacity>DL_Fundamental_Theorem_Network_Capacity</a></li></ul>
</main>
<nav class=links>
<a class=popUpButton href=#citePopUp>Cite</a>
<a class=popUpButton href=#downloadPopUp>Download</a>
<h4>PDFs</h4>
<a href=https://www.isa-afp.org/browser_info/current/AFP/Deep_Learning/outline.pdf>Proof
outline</a>
<a href=https://www.isa-afp.org/browser_info/current/AFP/Deep_Learning/document.pdf>Proof
document</a>
<a href=https://www.isa-afp.org/browser_info/current/AFP/Deep_Learning/session_graph.pdf>Dependencies</a>
</nav>
<div id=citePopUp class=overlay>
<a class=cancel href=#></a>
<div class=popup>
<h2>Cite</h2>
<a class=close href=#>&#215;</a>
<div>
<p style=display:none id=bibtexFileName>Deep_Learning-AFP</p>
<pre id=copyText>@article{Deep_Learning-AFP,
  author  = {Alexander Bentkamp},
  title   = {Expressiveness of Deep Learning},
  journal = {Archive of Formal Proofs},
  month   = November,
  year    = 2016,
  note    = {\url{http://isa-afp.org/entries/Deep_Learning.html},
            Formal proof development},
  ISSN    = {2150-914x},
}</pre>
<button id=copyBibtex>Copy</button> <a id=downloadBibtex>Download</a>
</div>
</div>
</div>
<div id=downloadPopUp class=overlay>
<a class=cancel href=#></a>
<div class=popup>
<h2>Download</h2>
<a class=close href=#>&#215;</a>
<a href=https://isa-afp.org/release/afp-Deep_Learning-current.tar.gz download>Download latest</a>
<p>Older releases:</p>
<ul><li>Isabelle2019:
<a href=https://isa-afp.org/release/afp-Deep_Learning-2019-06-11.tar.gz>
afp-Deep_Learning-2019-06-11.tar.gz
</a>
</li><li>Isabelle2018:
<a href=https://isa-afp.org/release/afp-Deep_Learning-2018-08-16.tar.gz>
afp-Deep_Learning-2018-08-16.tar.gz
</a>
</li><li>Isabelle2017:
<a href=https://isa-afp.org/release/afp-Deep_Learning-2017-10-10.tar.gz>
afp-Deep_Learning-2017-10-10.tar.gz
</a>
</li><li>Isabelle2016-1:
<a href=https://isa-afp.org/release/afp-Deep_Learning-2016-12-17.tar.gz>
afp-Deep_Learning-2016-12-17.tar.gz
</a>
</li><li>Isabelle2016:
<a href=https://isa-afp.org/release/afp-Deep_Learning-2016-11-10.tar.gz>
afp-Deep_Learning-2016-11-10.tar.gz
</a>
</li></ul>
</div>
</div>
</div>
</div>
</body>
</html>